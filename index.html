<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=800">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
        /* Color scheme stolen from Sergey Karayev */
        a {
            color: #1772d0;
            text-decoration: none;
        }

        a:focus, a:hover {
            color: #f09228;
            text-decoration: none;
        }

        body, td, th, tr, p, a {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px
        }

        .hp-photo {
            width: 240px;
            height: 240px;
            border-radius: 240px;
            -webkit-border-radius: 240px;
            -moz-border-radius: 240px;
        }

        strong {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px;
        }

        heading {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 24px;
        }

        papertitle {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 15px;
            font-weight: 700
        }

        name {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 32px;
        }

        .one {
            width: 160px;
            height: 160px;
            position: relative;
        }

        .two {
            width: 160px;
            height: 160px;
            position: absolute;
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }

        .fade {
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }

        span.highlight {
            background-color: #ffffd0;
        }
    </style>

    <title>Yong-Qiang Mao | University of Chinese Academy of Sciences</title>
    <!--<link rel="stylesheet" type="text/css" href="/imgs/css" >-->
    <link rel="icon" type="image/jpg" href="./imgs/CAS.jpeg">
</head>

<body>
<table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody>
    <tr>
        <td>


            <!--SECTION 1 -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="68%" valign="middle">
                        <p align="center">
                            <name>Yong-Qiang Mao (毛永强)</name>
                        </p>
                        <p align="justify">Yong-Qiang Mao is now a Ph.D. student in <a href="http://www.aircas.ac.cn/">Aerospace Information Research Institute 
                            (Institute of Electronics), Chinese Academy of Sciences</a> & <a href="https://eece.ucas.ac.cn/">School of Electronic, 
                            Electrical and Communication Engineering</a>, <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a>. 
                            His research advisors are <a href="http://people.ucas.ac.cn/~fukun">Prof. Kun Fu</a> and 
                            <a href="http://people.ucas.ac.cn/~sunxian">Prof. Xian Sun. </a>Yong-Qiang Mao received the B. E. degree from 
                            <a href="http://http://eis.whu.edu.cn/">Electronic Information School</a>, <a href="https://www.whu.edu.cn/">Wuhan University</a>, 
                            Wuhan, China, in 2019.
                            </br>
                        </p>
                        <p align="center">
                            <a href="mailto:Mao.YongQiang@ieee.org">Email</a> /
                            <a href="https://github.com/WingkeungM"> Github </a> /
                            <a href="https://github.com/WingkeungM"> Google Scholar </a> /
                            <a href="https://orcid.org/0000-0001-9256-3668"> ORCID </a>
                        </p>
                    </td>
                    <td align="right"><img class="hp-photo" src="./imgs/maoyongqiang.jpg" style="width: 240;"></td>
                </tr>
                </tbody>
            </table>

            <!--SECTION 2 -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td>
                        <heading>Research</heading>
                        <p align="justify">
                            Yong-Qiang Mao's research interests include remote sensing and computer vision, with a focus on 3D Perception (Point Cloud and Reconstruction),
                            Multimodal Remote Sensing (Semantic Segmentation and Object Detection), Large Foundation Models, Few-shot Learning.
                        </p>
                        <p align="justify">
                        <font color="FF2D2D">I will enter a postdoctoral position with a planned start date after June 2024.</font> <font color="FF2D2D"> 
                            I am also looking for scientific research collaborators. If you are interested in scientific research cooperation, 
                            please feel free to contact me.</font>
                      	<br>
                    </td>
                </tr>
                </tbody>
            </table>

            <!--SECTION 3 -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
                <tbody>
                <tr>
                    <td>
                        <heading>News</heading>
                        <p><strong>[2023/10]</strong> One paper about <b>few-shot segmantic segmentation</b> has been accepted by <b>IEEE TGRS</b>!                        
                        <p><strong>[2023/05]</strong> One paper about <b>UAV object detection</b> has been accepted by <b>ISPRS Journal</b>!                        
                        <p><strong>[2023/04]</strong> One paper about <b>building 3d reconstruction</b> has been accepted by <b>IEEE TGRS</b>!                        
                        <p><strong>[2023/02]</strong> One paper about <b>few-shot object detection</b> has been accepted by <b>IEEE TGRS</b>!
                        <p><strong>[2023/02]</strong> One paper about <b>object detection</b> has been accepted by <b>IEEE TGRS</b>!
                        <p><strong>[2023/01]</strong> We successfully held the <b>2023 IEEE GRSS Data Fusion Contest (DFC2023)</b>!
                        <p><strong>[2023/01]</strong> One paper about <b>semi-supervised segmentation</b> has been accepted by <b>IEEE TGRS</b>!
                        <p><strong>[2022/12]</strong> One paper about <b>cross-modal retrieval</b> has been accepted by <b>IJAG</b>!
                        <p><strong>[2022/12]</strong> One paper about <b>few-shot object detection</b> has been accepted by <b>AAAI2023</b>!
                        <p><strong>[2022/09]</strong> One paper about <b>multi-modal semantic localization</b> has been accepted by <b>IEEE TGRS</b>!
                        <p><strong>[2022/04]</strong> One paper about <b>ALS point cloud segmentation</b> has been accepted by <b>ISPRS Journal</b>!
                        <p><strong>[2021/12]</strong> One paper about <b>visual point cloud segmentation</b> has been accepted by <b>AAAI-DLG 2022</b>!
                        
                    </td>
                </tr>
                </tbody>
            </table>

            <!--SECTION 4 -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td>
                        <heading>Publications</heading>
                    </td>
                </tr>
                </tbody>
            </table>


           <!--SECTION 5 -->
           <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
            <tr>
                <td width="20%"><img src="./imgs/RFFSNet.png" alt="PontTuset" width="180"
                                     style="border-style: none"></td>
                <td width="80%" valign="top">
                    <p><a href="https://www.sciencedirect.com/science/article/pii/S0924271622000922?via%3Dihub">
                        <papertitle>Beyond single receptive field: A receptive field fusion-and-stratification network for airborne laser scanning point cloud classification
                        </papertitle>
                    </a>
                        <br><strong>Y. Mao</strong>, K. Chen, W. Diao, X. Sun, X. Lu, K. Fu, M. Weinmann<br>
                        <em>ISPRS Journal of Photogrammetry and Remote Sensing </em><strong>(IF=11.77)</strong><br>
                        <a href="https://www.sciencedirect.com/science/article/pii/S0924271622000922?via%3Dihub">Paper</a> /
                        <a href="https://github.com/WingkeungM/RFFS-Net">Code</a> /
                        <a href="https://www.sciencedirect.com/journal/isprs-journal-of-photogrammetry-and-remote-sensing/about/news#editor-s-article-choice-of-the-year-2022">Editor’s Article Choice of the Year 2022</a>
                        <!--<<iframe src="https://ghbtns.com/github-btn.html?user=&repo=&type=star&count=true&size=small"
                                frameborder="0" scrolling="0" width="120px" height="20px"></iframe>-->
                    <p align="justify" style="font-size:13px">  </p>
                    <p></p>
                </td>
            </tr>


            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/Building3D.png" alt="PontTuset" width="180"
                                         style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://ieeexplore.ieee.org/abstract/document/10103685/">
                            <papertitle>Elevation Estimation-Driven Building 3D Reconstruction from Single-View Remote Sensing Imagery
                            </papertitle>
                        </a>
                            <br><strong>Y. Mao</strong>, K. Chen, L. Zhao, W. Chen, D. Tang, W. Liu, Z. Wang, W. Diao, X. Sun, K. Fu<br>
                            <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                            <a href="https://ieeexplore.ieee.org/abstract/document/10103685/">Paper</a> /
                            <a >Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/MCRN.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://www.sciencedirect.com/science/article/pii/S156984322200259X">
                            <papertitle>MCRN: A Multi-source Cross-modal Retrieval Network for remote sensing
                            </papertitle>
                        </a>
                            <br>Z. Yuan, W. Zhang, C. Tian, <strong>Y. Mao</strong>, R. Zhou, H. Wang, K. Fu, X. Sun<br>
                            <em>International Journal of Applied Earth Observation and Geoinformation </em><strong>(IF=7.5)</strong><br>
                            <a href="https://www.sciencedirect.com/science/article/pii/S156984322200259X">Paper</a> /
                            <a href="https://github.com/xiaoyuan1996/MCRN">Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/ICPE.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/25274">
                            <papertitle>Breaking immutable: Information-coupled prototype elaboration for few-shot object detection
                            </papertitle>
                        </a>
                            <br>X. Lu, W. Diao, <strong>Y. Mao</strong>, J. Li, P. Wang, X. Sun, K. Fu<br>
                            <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI) 2023</em><br>
                            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25274">Paper</a> /
                            <a href="https://github.com/lxn96/ICPE">Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/TEMO.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://ieeexplore.ieee.org/abstract/document/10056362">
                            <papertitle>Few-shot object detection in aerial imagery guided by text-modal knowledge
                            </papertitle>
                        </a>
                            <br>X. Lu, X. Sun, W. Diao, <strong>Y. Mao</strong>, J. Li, Y. Zhang, P. Wang, K. Fu<br>
                            <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                            <a href="https://ieeexplore.ieee.org/abstract/document/10056362">Paper</a> /
                            <a  >Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/SeLo.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://arxiv.org/abs/2209.06515">
                            <papertitle>Learning to evaluate performance of multi-modal semantic localization
                            </papertitle>
                        </a>
                            <br>Z. Yuan, W. Zhang, C. Li, Z. Pan, <strong>Y. Mao</strong>, J. Chen, S. Li, H. Wang, X. Sun<br>
                            <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                            <a href="https://arxiv.org/abs/2209.06515">Paper</a> /
                            <a href="https://github.com/xiaoyuan1996/SemanticLocalizationMetrics">Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/DGConv.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://arxiv.org/pdf/2204.04944.pdf">
                            <papertitle>Semantic Segmentation for Point Cloud Scenes via Dilated Graph Feature Aggregation and Pyramid Decoders
                            </papertitle>
                        </a>
                            <br><strong>Y. Mao</strong>, X. Sun, W. Diao, K. Chen, Z. Guo, X. Lu, K. Fu<br>
                            <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI) Workshop 2022</em><br>
                            <a href="https://arxiv.org/pdf/2204.04944.pdf">Paper</a> /
                            <a  >Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>
                    <tr>
                        <td width="20%"><img src="./imgs/OGMN.png" alt="PontTuset" width="180"
                                                style="border-style: none"></td>
                        <td width="80%" valign="top">
                            <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0924271623000989">
                                <papertitle>OGMN: Occlusion-guided multi-task network for object detection in UAV images
                                </papertitle>
                            </a>
                                <br>X. Li, W. Diao, <strong>Y. Mao</strong>, P. Gao, X. Mao, X. Li, X. Sun<br>
                                <em>ISPRS Journal of Photogrammetry and Remote Sensing </em><strong>(IF=11.77)</strong><br>
                                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0924271623000989">Paper</a> /
                                <a  >Code</a> 
                            <p align="justify" style="font-size:13px"> </p>
                            <p></p>
                        </td>
                    </tr>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>
                    <tr>
                        <td width="20%"><img src="./imgs/PICS.png" alt="PontTuset" width="180"
                                                style="border-style: none"></td>
                        <td width="80%" valign="top">
                            <p><a href="https://ieeexplore.ieee.org/abstract/document/10024804">
                                <papertitle>PICS: Paradigms integration and contrastive selection for semisupervised remote sensing images semantic segmentation
                                </papertitle>
                            </a>
                                <br>X. Qi, <strong>Y. Mao</strong>, Y. Zhang, Y. Deng, H. Wei, L. Wang<br>
                                <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                                <a href="https://ieeexplore.ieee.org/abstract/document/10024804">Paper</a> /
                                <a  >Code</a> 
                            <p align="justify" style="font-size:13px"> </p>
                            <p></p>
                        </td>
                    </tr>

                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>
                    <tr>
                        <td width="20%"><img src="./imgs/LTD.png" alt="PontTuset" width="180"
                                                style="border-style: none"></td>
                        <td width="80%" valign="top">
                            <p><a href="https://ieeexplore.ieee.org/abstract/document/10034812">
                                <papertitle>Bridging the Gap Between Cumbersome and Light Detectors via Layer-Calibration and Task-Disentangle Distillation in Remote Sensing Imagery
                                </papertitle>
                            </a>
                                <br>Y. Zhang, Z. Yan, X. Sun, X. Lu, J. Li, <strong>Y. Mao</strong>, L. Wang<br>
                                <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                                <a href="https://ieeexplore.ieee.org/abstract/document/10034812">Paper</a> /
                                <a  >Code</a> 
                            <p align="justify" style="font-size:13px"> </p>
                            <p></p>
                        </td>
                    </tr>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>
                    <tr>
                        <td width="20%"><img src="./imgs/DMNet.png" alt="PontTuset" width="180"
                                                style="border-style: none"></td>
                        <td width="80%" valign="top">
                            <p><a href="https://ieeexplore.ieee.org/abstract/document/10288551/">
                                <papertitle>Bridging the Gap Between Cumbersome and Light Detectors via Layer-Calibration and Task-Disentangle Distillation in Remote Sensing Imagery
                                </papertitle>
                            </a>
                                <br>H. Bi, Y. Feng, Z. Yan, <strong>Y. Mao</strong>, W. Diao, H. Wang, X. Sun<br>
                                <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                                <a href="https://ieeexplore.ieee.org/abstract/document/10288551/">Paper</a> /
                                <a  >Code</a> 
                            <p align="justify" style="font-size:13px"> </p>
                            <p></p>
                        </td>
                    </tr>

                <!--SECTION 6 -->
                <table width="100%" align="center" border="0" cellspacing="0"
                       cellpadding="20">
                    <tbody>
                    <tr>
                        <td>
                            <heading>Projects</heading>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                                <tbody>
                                <tr>
                                    <td width="20%"><img src="./imgs/DFC2023.png" alt="PontTuset" width="180"
                                                         style="border-style: none"></td>
                                    <td width="80%" valign="top">
                                        <p><a>
                                            <papertitle>2023 IEEE GRSS Data Fusion Contest
                                            </papertitle>
                                        </a>
                                            <br>Large-Scale Fine-Grained Building Classification for Semantic Urban Reconstruction<br>
                                            <br><strong>Organization:</strong> Aerospace Information Research Institute, Chinese Academy of Sciences; Universität der Bundeswehr München; GEOVIS Earth Technology; IEEE GRSS<br>
                                            <a href="https://www.grss-ieee.org/technical-committees/image-analysis-and-data-fusion/?tab=data-fusion-contest">Website</a> /
                                            <a href="https://github.com/AICyberTeam/DFC2023-baseline">Baseline Code</a> 
                                        <p align="justify" style="font-size:13px"> </p>
                                        <p></p>
                                    </td>
                                </tr>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                                <tbody>
                                <tr>
                                    <td width="20%"><img src="./imgs/3DBuilding.gif" type="video/mp4"  width="180"
                                                            ></td>
                                    <td width="80%" valign="top">
                                        <p><a >
                                            <papertitle>Large-scale Urban Building Reconstruction
                                            </papertitle>
                                        </a>
                                            <br>Cooperate with GEOVIS Earth Technology<br>
                                            <br><strong>Y. Mao</strong>, K. Chen, X. Huang, X. Sun, and GEOVIS Earth Technology<br>
                                        <p align="justify" style="font-size:13px"> </p>
                                        <p></p>
                                    </td>
                                </tr>
                        </td>
                    </tr>
                    </tbody>
                </table>

                <!--SECTION 6 -->
                <table width="100%" align="center" border="0" cellspacing="0"
                    cellpadding="20">
                    <tbody>
                    <tr>
                        <td>
                            <heading>Education</heading>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                                <tbody>
                                <tr>
                                    <td width="20%"><img src="./imgs/UCAS.jpg" alt="PontTuset" width="150"
                                                        style="border-style: none"></td>
                                    <td width="80%" valign="top">
                                        <p><a href="https://www.ucas.ac.cn/">
                                            <papertitle>University of Chinese Academy of Sciences
                                            </papertitle>
                                        </a>
                                            <br><strong>Ph.D.</strong> Candidate from <a href="http://www.aircas.ac.cn/">Aerospace Information Research Institute 
                                                (Institute of Electronics), Chinese Academy of Sciences</a> & <a href="https://eece.ucas.ac.cn/">School of Electronic, 
                                                Electrical and Communication Engineering</a>, <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a>, Beijing, China<br>
                                            <br>Sep. 2019 - Now<br>
                                            <p align="justify" style="font-size:13px"> </p>
                                        <p></p>
                                    </td>
                                </tr>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                                <tbody>
                                <tr>
                                    <td width="20%"><img src="./imgs/whu.jpeg" alt="PontTuset" width="150"
                                                            style="border-style: none"></td>
                                    <td width="80%" valign="top">
                                        <p><a href="https://www.whu.edu.cn/">
                                            <papertitle>Wuhan University
                                            </papertitle>
                                        </a>
                                            <br><strong>B.E. degree</strong> from <a href="http://http://eis.whu.edu.cn/">Electronic Information School</a>, <a href="https://www.whu.edu.cn/">Wuhan University</a>, Wuhan, China<br>
                                            <br>Sep. 2015 - Jun.2019<br>
                                        <p align="justify" style="font-size:13px"> </p>
                                        <p></p>
                                    </td>
                                </tr>
                        </td>
                    </tr>
                    </tbody>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0"
                       cellpadding="20">
                    <tr>
                        <td width="100%" valign="middle">
                            <heading>Reviewer Services</heading>
                            <ul style="list-style-type:disc;">
                                <li>
                                    <a >IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
                                <li>
                                    <a >IIEEE/CVF International Conference on Computer Vision (ICCV)
                                <li>
                                    <a >European Conference on Computer Vision (ECCV)
                                <li>
                                    <a >Pattern Recognition (PR)
                                <li>
                                    <a >ISPRS Journal of Photogrammetry and Remote Sensing (ISPRS Journal)
                                <li>
                                    <a >Information Sciences
                                <li>
                                    <a >ACM Transactions on Multimedia Computing Communications and Applications (ACM TOMM)
                                <li>
                                    <a >IEEE Transactions on Geoscience and Remote Sensing (IEEE TGRS) 
                                <li>
                                    <a >IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (IEEE JSTARS)                                    
                            </ul>
                        </td>
                    </tr>
                </table>
                
                <table width="100%" align="center" border="0" cellspacing="0"
                       cellpadding="20">
                    <tr>
                        <td width="100%" valign="middle">
                            <heading>Awards</heading>
                            <ul style="list-style-type:disc;">
                                <li>
                                    <a >2022/12: 'Editor’s Article Choice of the Year 2022' of ISPRS Journal.
                                <li>
                                    <a >2022/02: 'Best Student Paper Award' of AAAI-DLG 2022.
                                <li>
                                    <a >2019/06: Outstanding Bachelor's Thesis.
                                <li>
                                    <a >2018/05: American Mathematical Contest In Modeling (MCM) Finalist (TOP 0.17%) Award.
                            </ul>
                        </td>
                    </tr>
                </table>

                <!--SECTION 9 -->
                <div style="clear:both;">
                    <p align="right"><font size="2">
                        <script type="text/javascript" id="clustrmaps"
                                src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=HRJUStWkCzVJNYj1eBbf2gulLkAey-vLYvOm9AqwlWY"></script>
                    </font></p>
                    <br/>
                </div>


                <!--SECTION 10 -->
                <table width="100%" align="center" border="0" cellspacing="0"
                       cellpadding="20">
                    <tbody>
                    <tr>
                        <td><br>
                            <!--<p align="right"><font size="3">Erd&ouml;s = ? </font><br> -->
                            <p align="right"><font size="2"> Copyright © 2022 &nbsp; Yong-Qiang Mao. All Rights Reserved.</a></font>
                            </p>
                        </td>
                    </tr>
                    </tbody>
                </table>


                </td>
                </tr>
                </tbody>
            </table>
</body>
</html>






