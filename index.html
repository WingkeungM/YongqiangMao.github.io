<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <meta name="viewport" content="width=800">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <style type="text/css">
        /* Color scheme stolen from Sergey Karayev */
        a {
            color: #1772d0;
            text-decoration: none;
        }

        a:focus, a:hover {
            color: #f09228;
            text-decoration: none;
        }

        body, td, th, tr, p, a {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px
        }

        .hp-photo {
            width: 240px;
            height: 240px;
            border-radius: 240px;
            -webkit-border-radius: 240px;
            -moz-border-radius: 240px;
        }

        strong {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 14px;
        }

        heading {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 24px;
        }

        papertitle {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 15px;
            font-weight: 700
        }

        name {
            font-family: 'Lato', Verdana, Helvetica, sans-serif;
            font-size: 32px;
        }

        .one {
            width: 160px;
            height: 160px;
            position: relative;
        }

        .two {
            width: 160px;
            height: 160px;
            position: absolute;
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }

        .fade {
            transition: opacity .2s ease-in-out;
            -moz-transition: opacity .2s ease-in-out;
            -webkit-transition: opacity .2s ease-in-out;
        }

        span.highlight {
            background-color: #ffffd0;
        }
    </style>

    <title>Yong-Qiang Mao | Tsinghua University</title>
    <!--<link rel="stylesheet" type="text/css" href="/imgs/css" >-->
    <link rel="icon" type="image/jpg" href="./imgs/THU.png">
</head>

<body>
<table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tbody>
    <tr>
        <td>
            <!--SECTION 1 -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="68%" valign="middle">
                        <p align="center">
                            <name>Yong-Qiang Mao (毛永强)</name>
                        </p>
                        <p align="justify">Yong-Qiang Mao is now a postdoctoral researcher at the <a href="https://www.ee.tsinghua.edu.cn/">Department of 
                            Electronic Engineering at Tsinghua University</a>. His advisor is You He. 
                            Yong-Qiang Mao received his Ph.D. degree in <a href="http://www.aircas.ac.cn/">Aerospace Information Research Institute 
                            (Institute of Electronics), Chinese Academy of Sciences</a> & <a href="https://eece.ucas.ac.cn/">School of Electronic, 
                            Electrical and Communication Engineering</a>, <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a>. 
                            His research advisors are <a href="http://people.ucas.ac.cn/~fukun">Prof. Kun Fu</a> and 
                            <a href="http://people.ucas.ac.cn/~sunxian">Prof. Xian Sun. </a>Yong-Qiang Mao received the B. E. degree from 
                            <a href="http://http://eis.whu.edu.cn/">Electronic Information School</a>, <a href="https://www.whu.edu.cn/">Wuhan University</a>, 
                            Wuhan, China, in 2019.
                            </br>
                        </p>
                        <p align="center">
                            <a href="mailto:Mao.YongQiang@ieee.org">Email</a> /
                            <a href="https://github.com/WingkeungM"> Github </a> /
                            <a href="https://scholar.google.com.hk/citations?user=3bWHKh0AAAAJ&hl=zh-CN"> Google Scholar </a> /
                            <a href="https://orcid.org/0000-0001-9256-3668"> ORCID </a>
                        </p>
                    </td>
                    <td align="right"><img class="hp-photo" src="./imgs/maoyongqiang.jpg" style="width: 240;"></td>
                </tr>
                </tbody>
            </table>

            <!--SECTION 2 -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td>
                        <heading>Research</heading>
                        <p align="justify">
                            Yong-Qiang Mao's research interests include remote sensing and computer vision, with a focus on 3D Perception (Point Cloud and Reconstruction),
                            Multimodal Remote Sensing (Semantic Segmentation and Object Detection), Cross-modal retrieval, Large Foundation Models, Few-shot Learning.
                        </p>
                        <p align="justify">
                        <font color="FF2D2D">I am currently a postdoctoral researcher at the Department of Electronic Engineering at Tsinghua University.</font> <font color="FF2D2D"> 
                            I am also looking for scientific research collaborators. If you are interested in scientific research cooperation, 
                            please feel free to contact me.</font>
                      	<br>
                    </td>
                </tr>
                </tbody>
            </table>

            <!--SECTION 3 -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="15">
                <tbody>
                <tr>
                    <td>
                        <heading>News</heading>                        
                        <p><strong>[2024/09]</strong> One paper about <b>few-shot segmantic segmentation</b> has been accepted by <b>IEEE TPAMI</b>!                        
                        <p><strong>[2024/09]</strong> One paper about <b>few-shot segmantic segmentation</b> has been accepted by <b>IEEE GRSL</b>! 
                        <p><strong>[2024/08]</strong> One paper about <b>multi-view stereo</b> has been accepted by <b>IEEE TGRS</b>!  
                        <p><strong>[2024/05]</strong> One paper about <b>ALS point cloud segmentation</b> has been released at by <b>arXiv</b>!  
                        <p><strong>[2024/05]</strong> One paper about <b>video and motion joint prediction</b> has been accepted by <b>IEEE TGRS</b>!  
                        <p><strong>[2024/02]</strong> One paper about <b>fine-grained 3D building model</b> has been accepted by <b>RSE</b>!  
                        <p><strong>[2023/10]</strong> One paper about <b>few-shot segmantic segmentation</b> has been accepted by <b>IEEE TGRS</b>!                        
                        <p><strong>[2023/05]</strong> One paper about <b>multi-task learning</b> has been accepted by <b>IGARSS2023</b>!                               
                        <p><strong>[2023/05]</strong> One paper about <b>end-to-end autonomous driving</b> has been released at by <b>arXiv</b>!  
                        <p><strong>[2023/05]</strong> One paper about <b>UAV object detection</b> has been accepted by <b>ISPRS Journal</b>!                        
                        <p><strong>[2023/04]</strong> One paper about <b>building 3d reconstruction</b> has been accepted by <b>IEEE TGRS</b>!                        
                        <p><strong>[2023/02]</strong> One paper about <b>few-shot object detection</b> has been accepted by <b>IEEE TGRS</b>!
                        <p><strong>[2023/02]</strong> One paper about <b>object detection</b> has been accepted by <b>IEEE TGRS</b>!
                        <p><strong>[2023/01]</strong> We successfully held the <b>2023 IEEE GRSS Data Fusion Contest (DFC2023)</b>!
                        <p><strong>[2023/01]</strong> One paper about <b>semi-supervised segmentation</b> has been accepted by <b>IEEE TGRS</b>!
                        <p><strong>[2022/12]</strong> One paper about <b>cross-modal retrieval</b> has been accepted by <b>IJAG</b>!
                        <p><strong>[2022/12]</strong> One paper about <b>few-shot object detection</b> has been accepted by <b>AAAI2023</b>!
                        <p><strong>[2022/09]</strong> One paper about <b>multi-modal semantic localization</b> has been accepted by <b>IEEE TGRS</b>!
                        <p><strong>[2022/07]</strong> One paper about <b>point cloud few-shot segmentation</b> has been accepted by <b>IEEE 3DV Oral</b>!
                        <p><strong>[2022/04]</strong> One paper about <b>ALS point cloud segmentation</b> has been accepted by <b>ISPRS Journal</b>!
                        <p><strong>[2021/12]</strong> One paper about <b>visual point cloud segmentation</b> has been accepted by <b>AAAI-DLG 2022</b>!
                        
                    </td>
                </tr>
                </tbody>
            </table>

            <!--SECTION 4 -->
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td>
                        <heading>Publications</heading>
                    </td>
                </tr>
                </tbody>
            </table>


           <!--SECTION 5 -->
           <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
            <tbody>
            <tr>
                <td width="20%"><img src="./imgs/RFFSNet.png" alt="PontTuset" width="180"
                                     style="border-style: none"></td>
                <td width="80%" valign="top">
                    <p><a href="https://www.sciencedirect.com/science/article/pii/S0924271622000922?via%3Dihub">
                        <papertitle>Beyond single receptive field: A receptive field fusion-and-stratification network for airborne laser scanning point cloud classification
                        </papertitle>
                    </a>
                        <br><strong>Y. Mao</strong>, K. Chen, W. Diao, X. Sun, X. Lu, K. Fu, M. Weinmann<br>
                        <em>ISPRS Journal of Photogrammetry and Remote Sensing </em><strong>(IF=11.77)</strong><br>
                        <a href="https://www.sciencedirect.com/science/article/pii/S0924271622000922?via%3Dihub">Paper</a> /
                        <a href="https://github.com/WingkeungM/RFFS-Net">Code</a> /
                        <a href="https://www.sciencedirect.com/journal/isprs-journal-of-photogrammetry-and-remote-sensing/about/news#editor-s-article-choice-of-the-year-2022">Editor’s Article Choice of the Year 2022</a>
                        <!--<<iframe src="https://ghbtns.com/github-btn.html?user=&repo=&type=star&count=true&size=small"
                                frameborder="0" scrolling="0" width="120px" height="20px"></iframe>-->
                    <p align="justify" style="font-size:13px">  </p>
                    <p></p>
                </td>
            </tr>


            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/Building3D.png" alt="PontTuset" width="180"
                                         style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://ieeexplore.ieee.org/abstract/document/10103685/">
                            <papertitle>Elevation Estimation-Driven Building 3D Reconstruction from Single-View Remote Sensing Imagery
                            </papertitle>
                        </a>
                            <br><strong>Y. Mao</strong>, K. Chen, L. Zhao, W. Chen, D. Tang, W. Liu, Z. Wang, W. Diao, X. Sun, K. Fu<br>
                            <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                            <a href="https://ieeexplore.ieee.org/abstract/document/10103685/">Paper</a> /
                            <a >Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/SDLMVS.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://arxiv.org/pdf/2405.17140">
                            <papertitle>SDL-MVS: View Space and Depth Deformable Learning Paradigm for Multi-View Stereo Reconstruction in Remote Sensing
                            </papertitle>
                        </a>
                            <br><strong>Y. Mao</strong>, H. Bi, L. Xu, K. Chen, Z. Wang, X. Sun, K. Fu<br>
                            <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                            <a href="https://arxiv.org/pdf/2405.17140">Paper</a> /
                            <a>Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/B2PM.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a >
                            <papertitle>Body Joint Boundary Prototype Match for Few Shot Remote Sensing Semantic Segmentation
                            </papertitle>
                        </a>
                            <br><strong>Y. Mao</strong>, Z. Jiang, Y. Liu, Y. Zhang, Y. Li, C. Yan, B. Zhang<br>
                            <em>IEEE Geoscience and Remote Sensing Letters</em> <strong>(IF=4.0)</strong><br>
                            <a >Paper</a> /
                            <a>Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/TDConvs.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://arxiv.org/pdf/2405.19735">
                            <papertitle>Twin Deformable Point Convolutions for Airborne Laser Scanning Point Cloud Classification
                            </papertitle>
                        </a>
                            <br><strong>Y. Mao</strong>, H. Bi, X. Li, K. Chen, Z. Wang, X. Sun, K. Fu<br>
                            <em>arXiv 2024</strong><br>
                            <a href="https://arxiv.org/pdf/2405.19735">Paper</a> /
                            <a>Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/BFG.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://arxiv.org/pdf/2208.06671">
                            <papertitle>Bidirectional Feature Globalization for Few-shot Semantic Segmentation of 3D Point Cloud Scenes
                            </papertitle>
                        </a>
                            <br><strong>Y. Mao</strong>, Z. Guo, X. Lu, Z. Yuan, H. Guo<br>
                            <em>2022 International Conference on 3D Vision (3DV2022, Oral)</strong><br>
                            <a href="https://arxiv.org/pdf/2208.06671">Paper</a> /
                            <a>Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/LIGHT.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://arxiv.org/pdf/2304.01090">
                            <papertitle>LIGHT: JOINT INDIVIDUAL BUILDING EXTRACTION AND HEIGHT ESTIMATION FROM SATELLITE IMAGES THROUGH A UNIFIED MULTITASK LEARNING NETWORK
                            </papertitle>
                        </a>
                            <br><strong>Y. Mao</strong>, X. Sun, X. Huang, K. Chen<br>
                            <em>IGARSS 2023-2023 IEEE International Geoscience and Remote Sensing Symposium (IGARSS2023)</em><br>
                            <a href="https://arxiv.org/pdf/2304.01090">Paper</a> /
                            <a  >Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/DGConv.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://arxiv.org/pdf/2204.04944.pdf">
                            <papertitle>Semantic Segmentation for Point Cloud Scenes via Dilated Graph Feature Aggregation and Pyramid Decoders
                            </papertitle>
                        </a>
                            <br><strong>Y. Mao</strong>, X. Sun, W. Diao, K. Chen, Z. Guo, X. Lu, K. Fu<br>
                            <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI) Workshops 2022</em><br>
                            <a href="https://arxiv.org/pdf/2204.04944.pdf">Paper</a> /
                            <a  >Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/ADMLP.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://arxiv.org/pdf/2305.10430">
                            <papertitle>Rethinking the Open-Loop Evaluation of End-to-End Autonomous Driving in nuScenes
                            </papertitle>
                        </a>
                            <br>J. Zhai*, Z. Feng*, J. Du*, <strong>Y. Mao*</strong>, J. Liu, Z. Tan, Y. Zhang, X. Ye, J. Wang (*Equal contribution)<br>
                            <em>Technical Report</strong><br>
                            <a href="https://arxiv.org/pdf/2305.10430">Paper</a> /
                            <a>Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/PAT.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://arxiv.org/pdf/2409.10389">
                            <papertitle>Prompt-and-Transfer: Dynamic Class-aware Enhancement for Few-shot Segmentation
                            </papertitle>
                        </a>
                            <br>H. Bi, Y. Feng, W. Diao, P. Wang, <strong>Y. Mao</strong>, K. Fu, H. Wang, X. Sun<br>
                            <em>IEEE Transactions on Pattern Analysis and Machine Intelligence </em><strong>(IF=20.8)</strong><br>
                            <a href="https://arxiv.org/pdf/2409.10389">Paper</a> /
                            <a>Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/GABLE.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://www.sciencedirect.com/science/article/pii/S0034425724000683">
                            <papertitle>GABLE: A first fine-grained 3D building model of China on a national scale from very high resolution satellite imagery
                            </papertitle>
                        </a>
                            <br>X. Sun, X. Huang, <strong>Y. Mao</strong>, T. Sheng, J. Li, Z. Wang, X. Lu, X. Ma, D. Tang, K. Chen<br>
                            <em>Remote Sensing of Environment </em><strong>(IF=11.1)</strong><br>
                            <a href="https://www.sciencedirect.com/science/article/pii/S0034425724000683">Paper</a> /
                            <a  >Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>
                    <tr>
                        <td width="20%"><img src="./imgs/OGMN.png" alt="PontTuset" width="180"
                                                style="border-style: none"></td>
                        <td width="80%" valign="top">
                            <p><a href="https://www.sciencedirect.com/science/article/abs/pii/S0924271623000989">
                                <papertitle>OGMN: Occlusion-guided multi-task network for object detection in UAV images
                                </papertitle>
                            </a>
                                <br>X. Li, W. Diao, <strong>Y. Mao</strong>, P. Gao, X. Mao, X. Li, X. Sun<br>
                                <em>ISPRS Journal of Photogrammetry and Remote Sensing </em><strong>(IF=11.77)</strong><br>
                                <a href="https://www.sciencedirect.com/science/article/abs/pii/S0924271623000989">Paper</a> /
                                <a  >Code</a> 
                            <p align="justify" style="font-size:13px"> </p>
                            <p></p>
                        </td>
                    </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/ICPE.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/25274">
                            <papertitle>Breaking immutable: Information-coupled prototype elaboration for few-shot object detection
                            </papertitle>
                        </a>
                            <br>X. Lu, W. Diao, <strong>Y. Mao</strong>, J. Li, P. Wang, X. Sun, K. Fu<br>
                            <em>Proceedings of the AAAI Conference on Artificial Intelligence (AAAI) 2023</em><br>
                            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25274">Paper</a> /
                            <a href="https://github.com/lxn96/ICPE">Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>
                    <tr>
                        <td width="20%"><img src="./imgs/PICS.png" alt="PontTuset" width="180"
                                                style="border-style: none"></td>
                        <td width="80%" valign="top">
                            <p><a href="https://ieeexplore.ieee.org/abstract/document/10024804">
                                <papertitle>PICS: Paradigms integration and contrastive selection for semisupervised remote sensing images semantic segmentation
                                </papertitle>
                            </a>
                                <br>X. Qi, <strong>Y. Mao</strong>, Y. Zhang, Y. Deng, H. Wei, L. Wang<br>
                                <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                                <a href="https://ieeexplore.ieee.org/abstract/document/10024804">Paper</a> /
                                <a  >Code</a> 
                            <p align="justify" style="font-size:13px"> </p>
                            <p></p>
                        </td>
                    </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/TAFormer.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://arxiv.org/pdf/2403.18238">
                            <papertitle>TAFormer: A Unified Target-Aware Transformer for Video and Motion Joint Prediction in Aerial Scenes

                            </papertitle>
                        </a>
                            <br>L. Xu, W. Lu, H. Yu, <strong>Y. Mao</strong>, H. Bi, C. Liu, X. Sun, K. Fu<br>
                            <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                            <a href="https://arxiv.org/pdf/2403.18238">Paper</a> /
                            <a  >Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/TEMO.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://ieeexplore.ieee.org/abstract/document/10056362">
                            <papertitle>Few-shot object detection in aerial imagery guided by text-modal knowledge
                            </papertitle>
                        </a>
                            <br>X. Lu, X. Sun, W. Diao, <strong>Y. Mao</strong>, J. Li, Y. Zhang, P. Wang, K. Fu<br>
                            <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                            <a href="https://ieeexplore.ieee.org/abstract/document/10056362">Paper</a> /
                            <a  >Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>
                    <tr>
                        <td width="20%"><img src="./imgs/DMNet.png" alt="PontTuset" width="180"
                                                style="border-style: none"></td>
                        <td width="80%" valign="top">
                            <p><a href="https://ieeexplore.ieee.org/abstract/document/10288551/">
                                <papertitle>Bridging the Gap Between Cumbersome and Light Detectors via Layer-Calibration and Task-Disentangle Distillation in Remote Sensing Imagery
                                </papertitle>
                            </a>
                                <br>H. Bi, Y. Feng, Z. Yan, <strong>Y. Mao</strong>, W. Diao, H. Wang, X. Sun<br>
                                <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                                <a href="https://ieeexplore.ieee.org/abstract/document/10288551/">Paper</a> /
                                <a  >Code</a> 
                            <p align="justify" style="font-size:13px"> </p>
                            <p></p>
                        </td>
                    </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/SeLo.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://arxiv.org/abs/2209.06515">
                            <papertitle>Learning to evaluate performance of multi-modal semantic localization
                            </papertitle>
                        </a>
                            <br>Z. Yuan, W. Zhang, C. Li, Z. Pan, <strong>Y. Mao</strong>, J. Chen, S. Li, H. Wang, X. Sun<br>
                            <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                            <a href="https://arxiv.org/abs/2209.06515">Paper</a> /
                            <a href="https://github.com/xiaoyuan1996/SemanticLocalizationMetrics">Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
                <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                    <tbody>
                    <tr>
                        <td width="20%"><img src="./imgs/LTD.png" alt="PontTuset" width="180"
                                                style="border-style: none"></td>
                        <td width="80%" valign="top">
                            <p><a href="https://ieeexplore.ieee.org/abstract/document/10034812">
                                <papertitle>Bridging the Gap Between Cumbersome and Light Detectors via Layer-Calibration and Task-Disentangle Distillation in Remote Sensing Imagery
                                </papertitle>
                            </a>
                                <br>Y. Zhang, Z. Yan, X. Sun, X. Lu, J. Li, <strong>Y. Mao</strong>, L. Wang<br>
                                <em>IEEE Transactions on Geoscience and Remote Sensing </em><strong>(IF=8.125)</strong><br>
                                <a href="https://ieeexplore.ieee.org/abstract/document/10034812">Paper</a> /
                                <a  >Code</a> 
                            <p align="justify" style="font-size:13px"> </p>
                            <p></p>
                        </td>
                    </tr>

            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/MCRN.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://www.sciencedirect.com/science/article/pii/S156984322200259X">
                            <papertitle>MCRN: A Multi-source Cross-modal Retrieval Network for remote sensing
                            </papertitle>
                        </a>
                            <br>Z. Yuan, W. Zhang, C. Tian, <strong>Y. Mao</strong>, R. Zhou, H. Wang, K. Fu, X. Sun<br>
                            <em>International Journal of Applied Earth Observation and Geoinformation </em><strong>(IF=7.5)</strong><br>
                            <a href="https://www.sciencedirect.com/science/article/pii/S156984322200259X">Paper</a> /
                            <a href="https://github.com/xiaoyuan1996/MCRN">Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                <tbody>
                <tr>
                    <td width="20%"><img src="./imgs/HeightFormer.png" alt="PontTuset" width="180"
                                            style="border-style: none"></td>
                    <td width="80%" valign="top">
                        <p><a href="https://www.mdpi.com/2072-4292/16/2/295">
                            <papertitle>HeightFormer: A Multilevel Interaction and Image-Adaptive Classification–Regression Network for Monocular Height Estimation with Aerial Images
                            </papertitle>
                        </a>
                            <br>Z. Chen, Y. Zhang, X. Qi, <strong>Y. Mao</strong>, X. Zhou, L. Wang, Y. Ge<br>
                            <em>Remote Sensing</em><strong>(IF=4.2)</strong><br>
                            <a href="https://www.mdpi.com/2072-4292/16/2/295">Paper</a> /
                            <a  >Code</a> 
                        <p align="justify" style="font-size:13px"> </p>
                        <p></p>
                    </td>
                </tr>
                <!--SECTION 6 -->
                <table width="100%" align="center" border="0" cellspacing="0"
                       cellpadding="20">
                    <tbody>
                    <tr>
                        <td>
                            <heading>Projects</heading>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                                <tbody>
                                <tr>
                                    <td width="20%"><img src="./imgs/DFC2023.png" alt="PontTuset" width="180"
                                                         style="border-style: none"></td>
                                    <td width="80%" valign="top">
                                        <p><a>
                                            <papertitle>2023 IEEE GRSS Data Fusion Contest
                                            </papertitle>
                                        </a>
                                            <br>Large-Scale Fine-Grained Building Classification for Semantic Urban Reconstruction<br>
                                            <br><strong>Organization:</strong> Aerospace Information Research Institute, Chinese Academy of Sciences; Universität der Bundeswehr München; GEOVIS Earth Technology; IEEE GRSS<br>
                                            <a href="https://www.grss-ieee.org/technical-committees/image-analysis-and-data-fusion/?tab=data-fusion-contest">Website</a> /
                                            <a href="https://github.com/AICyberTeam/DFC2023-baseline">Baseline Code</a> 
                                        <p align="justify" style="font-size:13px"> </p>
                                        <p></p>
                                    </td>
                                </tr>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                                <tbody>
                                <tr>
                                    <td width="20%"><img src="./imgs/3DBuilding.gif" type="video/mp4"  width="180"
                                                            ></td>
                                    <td width="80%" valign="top">
                                        <p><a >
                                            <papertitle>Large-scale Urban Building Reconstruction
                                            </papertitle>
                                        </a>
                                            <br>Cooperate with GEOVIS Earth Technology<br>
                                            <br><strong>Y. Mao</strong>, K. Chen, X. Huang, X. Sun, and GEOVIS Earth Technology<br>
                                        <p align="justify" style="font-size:13px"> </p>
                                        <p></p>
                                    </td>
                                </tr>
                        </td>
                    </tr>
                    </tbody>
                </table>

                <!--SECTION 6 -->
                <table width="100%" align="center" border="0" cellspacing="0"
                    cellpadding="20">
                    <tbody>
                    <tr>
                        <td>
                            <heading>Education</heading>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                                <tbody>
                                <tr>
                                    <td width="20%"><img src="./imgs/THU.png" alt="PontTuset" width="150"
                                                        style="border-style: none"></td>
                                    <td width="80%" valign="top">
                                        <p><a href="https://www.tsinghua.edu.cn/">
                                            <papertitle>Tsinghua University
                                            </papertitle>
                                        </a>
                                            <br><strong>Postdoctoral Researcher</strong> from <a href="https://www.ee.tsinghua.edu.cn/">Department of Electronic Engineering at Tsinghua University</a>, Beijing, China<br>
                                            <br>Jul. 2024 - Now<br>
                                            <p align="justify" style="font-size:13px"> </p>
                                        <p></p>
                                    </td>
                                </tr>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                                <tbody>
                                <tr>
                                    <td width="20%"><img src="./imgs/UCAS.jpg" alt="PontTuset" width="150"
                                                        style="border-style: none"></td>
                                    <td width="80%" valign="top">
                                        <p><a href="https://www.ucas.ac.cn/">
                                            <papertitle>University of Chinese Academy of Sciences
                                            </papertitle>
                                        </a>
                                            <br><strong>Ph.D. degree</strong> from <a href="http://www.aircas.ac.cn/">Aerospace Information Research Institute 
                                                (Institute of Electronics), Chinese Academy of Sciences</a> & <a href="https://eece.ucas.ac.cn/">School of Electronic, 
                                                Electrical and Communication Engineering</a>, <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a>, Beijing, China<br>
                                            <br>Sep. 2019 - Jun. 2024<br>
                                            <p align="justify" style="font-size:13px"> </p>
                                        <p></p>
                                    </td>
                                </tr>
                            <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
                                <tbody>
                                <tr>
                                    <td width="20%"><img src="./imgs/whu.jpeg" alt="PontTuset" width="150"
                                                            style="border-style: none"></td>
                                    <td width="80%" valign="top">
                                        <p><a href="https://www.whu.edu.cn/">
                                            <papertitle>Wuhan University
                                            </papertitle>
                                        </a>
                                            <br><strong>B.E. degree</strong> from <a href="http://http://eis.whu.edu.cn/">Electronic Information School</a>, <a href="https://www.whu.edu.cn/">Wuhan University</a>, Wuhan, China<br>
                                            <br>Sep. 2015 - Jun. 2019<br>
                                        <p align="justify" style="font-size:13px"> </p>
                                        <p></p>
                                    </td>
                                </tr>
                        </td>
                    </tr>
                    </tbody>
                </table>

                <table width="100%" align="center" border="0" cellspacing="0"
                       cellpadding="20">
                    <tr>
                        <td width="100%" valign="middle">
                            <heading>Reviewer Services</heading>
                            <ul style="list-style-type:disc;">
                                <li>
                                    <a >IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
                                <li>
                                    <a >IEEE/CVF International Conference on Computer Vision (ICCV)
                                <li>
                                    <a >European Conference on Computer Vision (ECCV)
                                <li>
                                    <a >International Conference on Pattern Recognition  (ICPR)
                                <li>
                                    <a >ISPRS Journal of Photogrammetry and Remote Sensing (ISPRS Journal)
                                <li>
                                    <a >Pattern Recognition (PR)
                                <li>
                                    <a >Pattern Recognition Letters (PRL) 
                                <li>
                                    <a >Information Sciences
                                <li>
                                    <a >International Journal of Computer Vision (IJCV)
                                <li>
                                    <a >Scientific Report
                                <li>
                                    <a >Multimedia Systems
                                <li>
                                    <a >ACM Transactions on Multimedia Computing Communications and Applications (ACM TOMM)
                                <li>
                                    <a >IEEE Transactions on Geoscience and Remote Sensing (IEEE TGRS) 
                                <li> 
                                    <a >IEEE Transactions on Circuits and Systems for Video Technology (IEEE TCSVT)
                                <li>
                                    <a >International Journal of Applied Earth Observation and Geoinformation (IJAG)
                                <li>
                                    <a >IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (IEEE JSTARS)    
                                <li>
                                    <a >IEEE Geoscience and Remote Sensing Letters (IEEE GRSL)
                            </ul>
                        </td>
                    </tr>
                </table>
                
                <table width="100%" align="center" border="0" cellspacing="0"
                       cellpadding="20">
                    <tr>
                        <td width="100%" valign="middle">
                            <heading>Awards</heading>
                            <ul style="list-style-type:disc;">
                                <li>
                                    <a >2022/12: 'Editor’s Article Choice of the Year 2022' of ISPRS Journal.
                                <li>
                                    <a >2022/02: 'Best Student Paper Award' of AAAI-DLG 2022.
                                <li>
                                    <a >2019/06: Outstanding Bachelor's Thesis.
                                <li>
                                    <a >2018/05: American Mathematical Contest In Modeling (MCM) Finalist (TOP 0.17%) Award.
                            </ul>
                        </td>
                    </tr>
                </table>

                <!--SECTION 9 -->
                <div style="clear:both;">
                    <p align="right"><font size="2">
                        <script type="text/javascript" id="clustrmaps"
                                src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=tt&d=HRJUStWkCzVJNYj1eBbf2gulLkAey-vLYvOm9AqwlWY"></script>
                    </font></p>
                    <br/>
                </div>


                <!--SECTION 10 -->
                <table width="100%" align="center" border="0" cellspacing="0"
                       cellpadding="20">
                    <tbody>
                    <tr>
                        <td><br>
                            <!--<p align="right"><font size="3">Erd&ouml;s = ? </font><br> -->
                            <p align="right"><font size="2"> Copyright © 2022 &nbsp; Yong-Qiang Mao. All Rights Reserved.</a></font>
                            </p>
                        </td>
                    </tr>
                    </tbody>
                </table>


                </td>
                </tr>
                </tbody>
            </table>
</body>
</html>






